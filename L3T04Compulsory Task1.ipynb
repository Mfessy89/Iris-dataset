{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a945108",
   "metadata": {},
   "source": [
    "To begin, we will read in the Iris dataset from the Iris.csv file and import the necessary libraries, and get the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01565981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0],\n",
       "       [ 0, 26]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Read in the Iris dataset\n",
    "df = pd.read_csv('Iris.csv')\n",
    "\n",
    "\n",
    "# Identify the independent variables\n",
    "X = df.drop(['Id', 'Species'], axis=1)\n",
    "\n",
    "# Encode the dependent variable\n",
    "y = df['Species'].apply(lambda x: 0 if x == 'Iris-setosa' else 1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Obtain a confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2589b3f",
   "metadata": {},
   "source": [
    "This confusion matrix tells us that there were 19 true negatives (samples that were correctly classified as not being Iris-setosa) and 26 true positives (samples that were correctly classified as being not Iris-setosa). There were no false negatives or false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f40fdb",
   "metadata": {},
   "source": [
    "Since there were no false positives or false negatives, we can predict that the model is likely to have high precision and high recall.\n",
    "\n",
    "We can calculate the accuracy, precision, and recall ourselves to check our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71dff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate the precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate the recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea3473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee617",
   "metadata": {},
   "source": [
    "Writing a code to evaluate precision, recall, accuracy:This code defines a function called evaluate that takes two arrays as input: y_true, which contains the true labels, and y_pred, which contains the predicted labels. The function calculates the number of true positives, false positives, true negatives, and false negatives, and then uses those values to calculate precision, recall, and accuracy. Finally, the function returns those values as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce8c14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate precision, recall, and accuracy\n",
    "def evaluate(y_true, y_pred):\n",
    "    # Calculate true positives, false positives, true negatives, and false negatives\n",
    "    tp = np.sum(np.logical_and(y_pred == 1, y_true == 1))\n",
    "    fp = np.sum(np.logical_and(y_pred == 1, y_true == 0))\n",
    "    tn = np.sum(np.logical_and(y_pred == 0, y_true == 0))\n",
    "    fn = np.sum(np.logical_and(y_pred == 0, y_true == 1))\n",
    "\n",
    "    # Calculate precision, recall, and accuracy\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "    return precision, recall, accuracy\n",
    "\n",
    "# Use the evaluate function to evaluate the model\n",
    "precision, recall, accuracy = evaluate(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06ead7",
   "metadata": {},
   "source": [
    "This confirms our prediction that the model is likely to have high precision and high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ede58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f826b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71e12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5053a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
